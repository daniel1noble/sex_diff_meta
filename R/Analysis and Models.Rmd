---
title: "Data Analysis and Meta-A Models"
author: "Lauren Harrison"
date: "28/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Load packages
```{r}
# Clear work space
  rm(list=ls())

# Install CRAN packages
  install.packages("pacman")

# Install orchard plot package
  devtools::install_github("itchyshin/orchard_plot", subdir = "orchaRd", force = TRUE, build_vignettes = TRUE); 
  devtools::install_github("daniel1noble/metaAidR"); 

  pacman::p_load(knitr, metafor, dplyr, kableExtra, tidyverse, rotl, phytools, GGally, R.rsp, patchwork, devtools, robumeta, ape, geiger, phytools, phangorn, rlist, orchaRd, metaAidR, corrplot)

# Source our own functions
  source("./R/func.R")

# Set the rerun object to FALSE so that you don't need to re-run all models again. Some take quite a lot of time to run. If FALSE, it will just re-load them. If you need to re-run, then simply just change to TRUE
rerun_models = FALSE
```

# 2. Load datasets
```{r}
    pers <- read.csv("./data/pers_data.csv")
bodysize <- read.csv("./data/bodysize_SSD.csv")

```

# 3. Fix "pers" dataset before we get started
```{r}

# Merge spp_names columns
  pers <- merge(x = pers,
                y = bodysize[,c("species_name", "m_BS", "m_SE", "f_BS", "f_SE", "measure", "SSD_index", "mating_system", "parental_care")],
                by="species_name", all.x=TRUE,  no.dups = TRUE)

# Just select the relevant columns for now to make life easier
  pers_new <- pers %>% 
          select(study_ID, year, species_name, mating_system, parental_care, SSD_index, taxo_group, measure, data_type, personality_trait, male_n, male_mean, m_SE_to_SD, female_n, female_mean, f_SE_to_SD, depend, directionality, spp_name_phylo)

# Check out some outliers
#  pers_new %>%
#  filter(is.na(SSD_index))

# Check species numbers
  pers_new %>%
  group_by(taxo_group) %>%
  summarise(species = length(unique(species_name)))

# Add in observation level random effect
  pers_new <- pers_new %>% 
            group_by(taxo_group) %>% 
            mutate(obs = 1:length( study_ID))
```

# 4. Calculate effect sizes (SMD and lnCVR)
```{r}
# calculating effect sizes

# SMD (Hedge's g)
  pers_new <- escalc(measure = "SMD", 
                n1i = male_n, n2i = female_n,
                m1i = male_mean, m2i = female_mean,
                sd1i = m_SE_to_SD, sd2i = f_SE_to_SD, data = pers_new, var.names=c("SMD_yi","SMD_vi"), append = TRUE)

# lnCVR
  pers_new <- escalc(measure = "CVR",
                       n2i = female_n, n1i = male_n,
                       m2i = female_mean, m1i = male_mean,
                       sd2i = f_SE_to_SD, sd1i = m_SE_to_SD, data = pers_new, var.names=c("CVR_yi","CVR_vi"))

# Find out why we have na? Seems like this is because SD in one of the sexes is zero. We could add a very small number here or assume 0 is NA and impute, but I would just exclude.
  #spp_drop <- pers_new %>%
  #filter(is.na(CVR_yi))

  #as.character(unique(spp_drop$spp_name_phylo))

# Exclude NAs
  pers_new <- pers_new %>%
              filter(!is.na(CVR_yi), !is.na(SMD_yi))
  dim(pers_new)            
```

# Looking closely at SSD
```{r}
pers_new_test <- split(pers_new, pers_new$taxo_group)

par(mfrow=c(3,2))
lapply(pers_new_test, function(x) hist(x$SSD_index))

dat <- pers_new %>%
filter(taxo_group == "bird" & personality_trait == "aggression") #looking at what's driving our strong aggression estimate

data.frame(pers_new %>%
group_by(taxo_group, personality_trait) %>%
filter(!is.na(SSD_index))%>%
summarise(N_ssd = length(SSD_index), N_spp = length(unique(spp_name_phylo))))

# plot it
ggplot(dat, aes(x=SSD_index, y = SMD_yi)) + 
geom_point() +
ylim(-5, 8)

```


# Plot effect sizes to see how they look
```{r}
# lnCVR
  hist(pers_new$CVR_yi)
  funnel(x = pers_new$CVR_yi, vi = pers_new$CVR_vi, yaxis="seinv", xlim = c(-10, 10))

#SMD
  hist(pers_new$SMD_yi)
  funnel(x = pers_new$SMD_yi, vi = pers_new$SMD_vi, yaxis="seinv")

# Effect sizes 3 and above
  pers_new %>%
  filter(SMD_yi > 3)
  
# checking SMD outliers
  # P038 is correct as reported in paper, but is a proportion
  # P029 has male SD wrong - paper says 64.4 but was recorded as 0.001 for some reason - amended in pers dataset
  # P017 is correct
  # P021 looks weird in paper too but is correct
  # P136 is correct
  # P014 is correct

#NOTE Lauren. Can you also check all the data on the top of the funnels. For some analyses the ratio of smallest to largest sampling variance is very large. This could be problems with data that have very high precision, could be incorrect sample sizes, SD or SE entered wrong. For example, check all data where Inverse SE > 14 in funnel for SMD and > 17 for lnCVR.  
  
# checking SMD outliers - inverse SE > 14
pers_new %>%
  filter(SMD_vi > 14)
```

### NEED TO DO BEFORE RUNNING PROPER MODELS ### 
1. Need to transform proportions to logits, then to Hedge's g?  
2. Scores - cut them out? 
    See section 10 for these two points
3. Flip signs where indicated 
    Done

# Lets flip signs of effects for SMD
The directional meaning of effect sizes vary depending on the specific units and trait being measured. The data has a directionality column that tells one if the meaning should be reversed (1) or left the same. 

```{r}
   pers_new$directionality <- ifelse(is.na(pers_new$directionality), 0, 1)

      pers_new$SMD_yi_flip <- ifelse(pers_new$directionality == 1, pers_new$SMD_yi*(-1), pers_new$SMD_yi)
```
# Prepare the phylogenic trees
For each taxonomic group the phylogenetic trees have been constructed. We'll use these trees for multi-level meta-analytic models throughout. 

```{r}
    
    # Find all tree file names
    tree_files <- paste0("./trees/", list.files("./trees"))[-1]

    # Read in bird trees (100) and take the average tree as consensus tree. Only need to do this once, and then re-write the file to make things easier. Note that here we are just writing the consensus tree
        #tree_bird <- read_birds(tree_files[1])
        #write.tree(tree_bird, "bird_species.nwk")
    
    # Get the rest of the taxa    
      trees <- lapply(tree_files, function(x) read.tree(x))
      names <- gsub("./trees/", "", tree_files)
      names(trees) <- names

    # Plot the trees and see how they look
      par(mfrow = c(1,5), mar = c(1,1,1,1))
      lapply(trees, function(x) plot(x, cex = 1))

    # Check that they are ultrametric
      lapply(trees, function(x) is.ultrametric(x))

    # Check that all names in the phylogeny are also in the data
      taxa_data_list <- split(pers_new, pers_new$taxo_group)
      
      other_groups <- mapply(x = taxa_data_list, 
                             y = trees, 
                             function(x,y) tree_checks(x,y, "spp_name_phylo", type = "checks"))

          #Print out each taxon group
      for(i in colnames(other_groups)){
            print(i)
            print(other_groups[,i] )
      }
      

      # Now we are ready to prune trees so that we get tree names match with species in data
      pruned_trees <- mapply(x = taxa_data_list, 
                             y = trees, 
                             function(x,y) tree_checks(x,y, "spp_name_phylo", type = "prune"))

      # Check that this has been done correctly
        re_checks <- mapply(x = taxa_data_list, 
                             y = pruned_trees, 
                             function(x,y) tree_checks(x,y, "spp_name_phylo", type = "checks"))
        
      for(i in colnames(re_checks)){
            print(i)
            print(re_checks[,i] )
      }

    # Extract the phylogenetic correlation matrices
            phylo_vcv <- lapply(pruned_trees, function(x) vcv(x, corr = TRUE))

```

# 5. models
Let's run the first bunch of models on the whole dataset. We'll start off with intercept only multi-level meta-analytic models, then move to multi-level meta-regression models. The functions in `func.R` should be consulted to see precisely what models are being fit across the taxonomic groups

```{r}
# Now we can fit some models. First our MLMA intercept only models, across each taxa. 

#NOTE Lauren: There are some issues with lnCVR models. Ratio of sampling variances are very large, probably because of outliers. I suggest removing outliers and checking model results don't change.

  if(rerun_models == TRUE){
    MLMA_models <- meta_model_fits(pers_new, phylo_vcv, type = "int")
    saveRDS(MLMA_models, "./output/MLMA_models_int")
  }else{
    MLMA_models <- readRDS("./output/MLMA_models_int")
  }


# View model results. Warning messages exist because there are NA values for lnCVR. These can be removed from the data. We can also get from these models estimates of heterogeneity from our models. Here we need the sampling variance vector and also the models for SMD and CVR. We can then use multivariate apply (mapply) across these lists

  split_taxa <- split(pers_new, pers_new$taxo_group)
    smd_mods <- MLMA_models["SMD",]
  lnCVR_mods <- MLMA_models["lnCVR",]

# From these models we can get I2 estimates. I'll show an example with birds. study_ID is the between study heterogeneity. Just pay attention to the "phylo", that tels sif there is a phylogenetic signal and the strength of that signal. Total I2 is testing how much heterogeneity you have beyond sampling variance.
  birds_smd = I2(smd_mods[[1]], v = split_taxa[[1]]$SMD_vi, phylo = "spp_name_phylo")
  birds_CVR = I2(lnCVR_mods[[1]], v = split_taxa[[1]]$CVR_vi, phylo = "spp_name_phylo")
  
# checking I2 without the phylo vcv
  birds_smd = I2(smd_mods[[1]], v = split_taxa[[1]]$SMD_vi, phylo = FALSE)
  birds_CVR = I2(lnCVR_mods[[1]], v = split_taxa[[1]]$CVR_vi, phylo = FALSE) # nothing changes-need to rerun models, take things out

# Finding I2 for the remaining species.
  fish_smd = I2(smd_mods[[2]], v = split_taxa[[2]]$SMD_vi, phylo = "spp_name_phylo")
  fish_CVR = I2(lnCVR_mods[[2]], v = split_taxa[[2]]$CVR_vi, phylo = "spp_name_phylo")
  invert_smd = I2(smd_mods[[3]], v = split_taxa[[3]]$SMD_vi, phylo = "spp_name_phylo")
  invert_CVR = I2(lnCVR_mods[[3]], v = split_taxa[[3]]$CVR_vi, phylo = "spp_name_phylo")
  mammal_smd = I2(smd_mods[[4]], v = split_taxa[[4]]$SMD_vi, phylo = "spp_name_phylo")
  mammal_CVR = I2(lnCVR_mods[[4]], v = split_taxa[[4]]$CVR_vi, phylo = "spp_name_phylo")
  reptile_smd = I2(smd_mods[[5]], v = split_taxa[[5]]$SMD_vi, phylo = "spp_name_phylo")
  reptile_CVR = I2(lnCVR_mods[[5]], v = split_taxa[[5]]$CVR_vi, phylo = "spp_name_phylo")
  
# Now that we have our list of models, we can extract the estimates, CIs and even prediction intervals. Use our new orchaRd package to do this. 

  MLMA_estimates_SMD <- plyr::ldply(lapply(smd_mods, function(x) print(mod_results(x, mod = "Int"))))

  MLMA_estimates_lnCVR <- plyr::ldply(lapply(lnCVR_mods, function(x) print(mod_results(x, mod = "Int"))))

```

# 6. Run random effects models for each of the personality traits separately, and for each of the taxonomic groups?
```{r}
# OK, now we can have a look at a sensible model that looks at moderators. We'll look first at the personality trait moderator. Note, we'll estimate the mean for each of the categorical levels because we are not so much interested in whether the means differ, but whether or not males and females differ in any of these traits

  if(rerun_models == TRUE){
      MLMR_models_pers_trait <- meta_model_fits(pers_new, phylo_vcv, type = "pers")
      saveRDS(MLMR_models_pers_trait, "./output/MLMR_models_pers_trait")
    } else{
      MLMR_models_pers_trait <- readRDS("./output/MLMR_models_pers_trait")
    }
# Extract the SMD and lnCVR results
    smd_mods_pers <- MLMR_models_pers_trait["SMD",]
  lnCVR_mods_pers <- MLMR_models_pers_trait["lnCVR",]

# Get the combined estimates from them all
   MLMA_estimates_SMD_pers <- plyr::ldply(lapply(smd_mods_pers, function(x) print(mod_results(x, mod = "personality_trait"))))
 MLMA_estimates_lnCVR_pers <- plyr::ldply(lapply(lnCVR_mods_pers, function(x) print(mod_results(x, mod = "personality_trait"))))

 # You probably want to add in n and k to these dataframes
  n_k<- pers_new %>%
      group_by(taxo_group, personality_trait) %>%
      summarise(n = n(), k = length(unique(study_ID)))

  MLMA_estimates_SMD_pers <- data.frame(MLMA_estimates_SMD_pers, n_k[,c("n", "k")])
  MLMA_estimates_lnCVR_pers <- data.frame(MLMA_estimates_lnCVR_pers, n_k[,c("n", "k")])

```

# 7. Now have a look at how SSD interacting with personality trait type. Here we are not estimating a intercept either, so each intercept varies by trait category and each slope as well. Note that there are lots of warnings, but these are the result of many levels not being present in taxa groups. Note also here that the SSD_index is scaled to make the interpretation of the intercepts a little more sensible

```{r}

# remove NAs from SSD data before running the model
# Exclude NAs
  pers_new <- pers_new %>%
              filter(!is.na(SSD_index))
  dim(pers_new)    
  
# flip SSD index so males > females = positive value instead of males < females = positive
# pers_new$SSD_index_flip <- pers_new$SSD_index*(-1) - this makes females the positive value when larger, so ignore this
  
if(rerun_models == TRUE){
      MLMR_models_pers_SSD <- meta_model_fits(pers_new, phylo_vcv, type = "pers_SSD")
      saveRDS(MLMR_models_pers_SSD, "./output/MLMR_models_pers_SSD")
    } else{
      MLMR_models_pers_SSD <- readRDS("./output/MLMR_models_pers_SSD")
    }

# Extract the SMD and lnCVR results
    smd_mods_pers_SSD <- MLMR_models_pers_SSD["SMD",]
  lnCVR_mods_pers_SSD <- MLMR_models_pers_SSD["lnCVR",]

# NOTE: Lauren you'll need to write a function to extract estimates here as the mod_results from OrchaRd only works with a single categorical moderator. Or, you can manually extract, but I don't recommend.
  
# Can we add in n and k to these dataframes?

```

# 8. We can also have a look at fitting a model that estimates an interaction between mating system (a second proxy for SSD) and 
```{r}

# NOTE Lauren: Seems to be some problems here, probably just lots of missing data. You're probably just going to have to select the taxon group, corresponding tree and subset the data and selectively run a subset of models. 
  if(rerun_models == TRUE){
      MLMR_models_pers_mating <- meta_model_fits(pers_new, phylo_vcv, type = "pers_mate")
      saveRDS(MLMR_models_pers_mating, "./output/MLMR_models_pers_mating")
    } else{
      MLMR_models_pers_mating <- readRDS("./output/MLMR_models_pers_mating")
    }

# Extract the SMD and lnCVR results
    smd_mods_pers_mating <- MLMR_models_pers_mating["SMD",]
  lnCVR_mods_pers_mating <- MLMR_models_pers_mating["lnCVR",]

```

# 9. Run random effects models for each of the parental care separately, and for each of the taxonomic groups
```{r}
#NOTE Lauren: This is problematic given the huge amount of missing data here. So, you'll need to exclude the data and also reptiles and any taxa. The phylogeny also needs to be trimmed again, which I have done. But, looking below, a lot of this data on certain groups comes from one study. I don't know that parental care will be too useful 

# OK, now we can have a look at a sensible model that looks at moderators. We'll look first at the personality trait moderator. Note, we'll estimate the mean for each of the categorical levels because we are not so much interested in whether the means differ, but whether or not males and females differ in any of these traits. 

# Because this is so much missing data in parental care and reptiles are hopeless, we can exclude these taxa. 
    pers_new_parentalcare <- as.data.frame(pers_new %>%
    filter(!is.na(parental_care) & !taxo_group == "reptilia"))

  #Check that this has been done correctly. No reptiles and no NA levels with parental care
      pers_new_parentalcare %>%
      group_by(taxo_group, parental_care) %>%
      summarise(n = n(), studies = length(unique(study_ID)))

# Because we excluded so much, we need to ditch species we lost as a result of this
    pers_new_parentalcare_list <- split(pers_new_parentalcare, pers_new_parentalcare$taxo_group, drop = TRUE)

     pruned_trees_PC <- mapply(x = pers_new_parentalcare_list, 
                             y = trees[-5], # drop out reptiles
                             function(x,y) tree_checks(x,y, "spp_name_phylo", type = "prune"))

      # Check that this has been done correctly
        re_checks <- mapply(x = pers_new_parentalcare_list, 
                             y = pruned_trees_PC, 
                             function(x,y) tree_checks(x,y, "spp_name_phylo", type = "checks"))
        
      for(i in colnames(re_checks)){
            print(i)
            print(re_checks[,i] )
      }

# Extract the phylogenetic correlation matrices
            phylo_vcv_PC <- lapply(pruned_trees_PC, function(x) vcv(x, corr = TRUE))

  MLMR_models_par_care <- meta_model_fits(pers_new_parentalcare, phylo_vcv_PC, type = "parent_care")

# Extract the SMD and lnCVR results
    smd_mods_par_care <- MLMR_models_par_care["SMD",]
  lnCVR_mods_par_care <- MLMR_models_par_care["lnCVR",]

# Get the combined estimates from them all
   MLMA_estimates_SMD_par_care <- plyr::ldply(lapply(smd_mods_par_care, function(x) print(mod_results(x, mod = "parental_care"))))
 MLMA_estimates_lnCVR_par_care <- plyr::ldply(lapply(lnCVR_mods_par_care, function(x) print(mod_results(x, mod = "parental_care"))))

```

# 10. TO DO Sensitivity Analyses: 

1) We need to refit these models accounting for any dependency resulting from the same traits measured on the same animals (likely a big one) and any other shared covariance. Probably this is best added to the residual variance matrix as opposed to the sampling covariance. 
2) Need to test if there are differences between proportion data; include moderator in a simple model. 
3) Need to test if there are differences between score data; include moderator in a simple model. 

```{r}
 # Create the dependency matrices; try 3 levels of rho = 0.3, 0.5, 0.8
      
      pers_new <- data.frame(pers_new %>%
      group_by(taxo_group) %>%
      mutate(depend_n = paste0(study_ID, "_", depend)))
    

    split_taxa <- split(pers_new, pers_new$taxo_group)

  D_matrices_0.3 <- lapply(split_taxa, function(x) make_VCV_matrix(x, V = x$SMD_vi, cluster = "depend_n", obs = "obs", type = "cor", rho = 0.3))

  # NOTE: Lauren –Have a look and make sure these matrices are correct. You should see correlations for numbers within studies that match. Usually these are blocks of effects along the diagonal. IF you have ones far away form the signal, then you need to check these. Here is an example with reptiles
    corrplot(D_matrices_0.3[[5]], tl.cex= 0.3) # Reptiles
    # write.csv(D_matrices_0.3[[5]], "reptiles_D.csv") # Can write it and have a closer look too

    #Once happy with the D matrices you can refit models, but just modify as follows:

    fit_int_MLMAmodel_D <- function(data, phylo_vcv, D){

          lnCVR <- metafor::rma.mv(CVR_yi ~ 1, V = CVR_vi, random = list(~1|study_ID, ~1|spp_name_phylo, ~1|obs), R = list(spp_name_phylo=phylo_vcv, obs = D), data = data)

            SMD <- metafor::rma.mv(SMD_yi_flip ~ 1, V = SMD_vi, random = list(~1|study_ID, ~1|spp_name_phylo, ~1|obs), R = list(spp_name_phylo=phylo_vcv, obs = D), data = data) 

          return(list(SMD = SMD, 
                lnCVR = lnCVR))
}


```


